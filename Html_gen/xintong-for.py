import numpy as np
import tensorflow_datasets as tfds
from PIL import Image
from IPython import display
import os
import matplotlib.pyplot as plt
import pandas as pd
import random
import tensorflow as tf
from tqdm import tqdm
from matplotlib import font_manager as fm
import spacy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from collections import defaultdict, Counter
import pprint
import sys
from datetime import datetime
from jinja2 import Template

# åˆ›å»ºæ—¥å¿—ç›®å½•å’Œæ–‡ä»¶
log_dir = "./xthLog"
os.makedirs(log_dir, exist_ok=True)
time_stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
log_file_path = os.path.join(log_dir, f"{time_stamp}.txt")

# ä¿å­˜åŸå§‹çš„stdout
original_stdout = sys.stdout

# åˆ›å»ºä¸€ä¸ªç±»æ¥åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
class TeeOutput:
    def __init__(self, *files):
        self.files = files
    
    def write(self, text):
        for f in self.files:
            f.write(text)
            f.flush()
    
    def flush(self):
        for f in self.files:
            f.flush()

# æ‰“å¼€æ—¥å¿—æ–‡ä»¶å¹¶é‡å®šå‘è¾“å‡º
log_file = open(log_file_path, 'w', encoding='utf-8')
sys.stdout = TeeOutput(original_stdout, log_file)

print(f"æ—¥å¿—æ–‡ä»¶å·²åˆ›å»º: {log_file_path}")
print(f"ç¨‹åºå¼€å§‹æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 50)


nlp = spacy.load("en_core_web_sm")
font_path = "/home2/qrchen/GillSans.ttc"
font_prop = fm.FontProperties(fname=font_path)


# dataset_name is the nickname of the dataset
def dataset2path(dataset_name):
    import subprocess
    import re
    
    try:
        # è°ƒç”¨ gsutil ls å‘½ä»¤è·å–æ‰€æœ‰ç‰ˆæœ¬
        cmd = f'gsutil ls gs://gresearch/robotics/{dataset_name}/'
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"è­¦å‘Š: æ— æ³•è®¿é—® gs://gresearch/robotics/{dataset_name}/ï¼Œé”™è¯¯ä¿¡æ¯: {result.stderr}")
            # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç‰ˆæœ¬å·é€»è¾‘
            if dataset_name == 'robo_net':
                default_version = '1.0.0'
            elif dataset_name in ['language_table', 'robo_set', 'spoc',"DROID"]:
                default_version = '0.0.1'
            elif dataset_name in ['droid']:
                default_version = '1.0.0'
            else:
                default_version = '0.1.0'
            print(f"ä½¿ç”¨é»˜è®¤ç‰ˆæœ¬å·: {default_version}")
            return f'gs://gresearch/robotics/{dataset_name}/{default_version}'
        
        # è§£æè¾“å‡ºï¼ŒæŸ¥æ‰¾ç‰ˆæœ¬å·æ ¼å¼ æ•°å­—.æ•°å­—.æ•°å­— æˆ– æ•°å­—.æ•°å­—
        lines = result.stdout.strip().split('\n')
        versions = []
        
        for line in lines:
            if line.strip():
                # æå–è·¯å¾„ä¸­çš„ç‰ˆæœ¬å·éƒ¨åˆ†
                # æ ¼å¼: gs://gresearch/robotics/{dataset_name}/{version}/
                match = re.search(rf'gs://gresearch/robotics/{re.escape(dataset_name)}/(\d+\.\d+(?:\.\d+)?)', line)
                if match:
                    version_str = match.group(1)
                    versions.append(version_str)
        
        if not versions:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç‰ˆæœ¬å·ï¼Œä½¿ç”¨é»˜è®¤ç‰ˆæœ¬")
            # ä½¿ç”¨é»˜è®¤ç‰ˆæœ¬å·é€»è¾‘
            if dataset_name == 'robo_net':
                backup_version = '1.0.0'
            elif dataset_name in ['language_table', 'robo_set', 'spoc',"DROID"]:
                backup_version = '0.0.1'
            elif dataset_name in ['droid']:
                backup_version = '1.0.0'
            else:
                backup_version = '0.1.0'
            print(f"ä½¿ç”¨é»˜è®¤ç‰ˆæœ¬å·: {backup_version}")
            return f'gs://gresearch/robotics/{dataset_name}/{backup_version}'
        
        # å¯¹ç‰ˆæœ¬å·è¿›è¡Œæ’åºï¼Œæ‰¾åˆ°æœ€å°ç‰ˆæœ¬
        def version_key(version_str):
            try:
                parts = version_str.split('.')
                return tuple(int(part) for part in parts)
            except ValueError:
                # å¦‚æœç‰ˆæœ¬å·æ ¼å¼æœ‰é—®é¢˜ï¼Œè¿”å›ä¸€ä¸ªå¾ˆå¤§çš„æ•°å­—ä½œä¸ºæ’åºé”®
                return (999, 999, 999)
        
        # å»é‡ç‰ˆæœ¬å·åˆ—è¡¨
        unique_versions = list(set(versions))
        min_version = min(unique_versions, key=version_key)
        print(f"æ•°æ®é›† {dataset_name} æ‰¾åˆ°ç‰ˆæœ¬: {versions}ï¼Œå»é‡å: {unique_versions}ï¼Œé€‰æ‹©æœ€å°ç‰ˆæœ¬: {min_version}")
        print(f'æ­£å¸¸è¿”å› gs://gresearch/robotics/{dataset_name}/{min_version}')
        return f'gs://gresearch/robotics/{dataset_name}/{min_version}'
        
    except Exception as e:
        print(f"é”™è¯¯: è·å–æ•°æ®é›† {dataset_name} ç‰ˆæœ¬æ—¶å‡ºé”™: {e}")
        # å‡ºé”™æ—¶ä½¿ç”¨é»˜è®¤ç‰ˆæœ¬å·é€»è¾‘
        if dataset_name == 'robo_net':
            fallback_version = '1.0.0'
        elif dataset_name in ['language_table', 'robo_set', 'spoc',"DROID"]:
            fallback_version = '0.0.1'
        elif dataset_name in ['droid']:
            fallback_version = '1.0.0'
        else:
            fallback_version = '0.1.0'
        print(f"ä½¿ç”¨é»˜è®¤ç‰ˆæœ¬å·: {fallback_version}")
        print(f'å¼‚å¸¸ gs://gresearch/robotics/{dataset_name}/{min_version}')
        return f'gs://gresearch/robotics/{dataset_name}/{fallback_version}'

# ============ å·¥å…·å‡½æ•° ============
def depth_to_color_img(depth):
    """å°†depthè½¬ä¸ºå½©è‰²å›¾åƒ"""
    d = depth.copy()
    d = (d - np.nanmin(d)) / (np.nanmax(d) - np.nanmin(d) + 1e-8)
    cm = plt.get_cmap('jet')
    colored = cm(d)[:, :, :3]  # åªè¦RGBï¼Œä¸è¦alpha
    colored = (colored * 255).astype(np.uint8)
    return colored

def as_gif(images, path="temp.gif", resize_factor=0.5):
    """ç”ŸæˆGIFæ–‡ä»¶"""
    if resize_factor != 1.0:
        resized_images = []
        for img in images:
            width, height = img.size
            new_size = (int(width * resize_factor), int(height * resize_factor))
            resized_images.append(img.resize(new_size, Image.Resampling.LANCZOS))
        images = resized_images
    
    images[0].save(path, save_all=True, append_images=images[1:], duration=int(1000/15), loop=0)
    gif_bytes = open(path,"rb").read()
    return gif_bytes

def get_language_instruction(episode, config):
    """æå–è¯­è¨€æŒ‡ä»¤"""
    for step in episode["steps"]:
        lang_inst = step[config["language_field"]].numpy()
        if isinstance(lang_inst, bytes):
            lang_inst = lang_inst.decode('utf-8')
        return lang_inst
    return ""

def center_pad_images_to_max_size(images):
    """å°†å›¾åƒåˆ—è¡¨å±…ä¸­å¯¹é½å¹¶å¡«å……åˆ°æœ€å¤§å°ºå¯¸"""
    if not images:
        return images
    
    # æ‰¾åˆ°æœ€å¤§çš„é«˜åº¦å’Œå®½åº¦
    max_height = max(img.shape[0] for img in images)
    max_width = max(img.shape[1] for img in images)
    
    padded_images = []
    for img in images:
        height, width = img.shape[:2]
        
        # è®¡ç®—å±…ä¸­å¯¹é½éœ€è¦çš„å¡«å……
        pad_height_total = max_height - height
        pad_width_total = max_width - width
        
        # åˆ†åˆ«è®¡ç®—ä¸Šä¸‹ã€å·¦å³çš„å¡«å……é‡ï¼ˆå±…ä¸­å¯¹é½ï¼‰
        pad_top = pad_height_total // 2
        pad_bottom = pad_height_total - pad_top
        pad_left = pad_width_total // 2
        pad_right = pad_width_total - pad_left
        
        # ä½¿ç”¨é»‘è‰²å¡«å…… (0å€¼)
        if len(img.shape) == 3:  # RGBå›¾åƒ
            padded_img = np.pad(img, 
                              ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), 
                              mode='constant', 
                              constant_values=0)
        else:  # ç°åº¦å›¾åƒ
            padded_img = np.pad(img, 
                              ((pad_top, pad_bottom), (pad_left, pad_right)), 
                              mode='constant', 
                              constant_values=0)
        
        padded_images.append(padded_img)
    
    return padded_images

def process_single_step(obs, config):
    """å¤„ç†å•å¸§æ•°æ®ï¼Œè¿”å›æ‹¼æ¥çš„å›¾åƒå’Œæ·±åº¦å›¾åƒ"""
    # æå–RGBå›¾åƒ
    rgb_images = []
    for field in config["image_fields"]:
        # å¤„ç†åµŒå¥—å›¾åƒè·¯å¾„
        if isinstance(field, tuple):
            field_name, sub_field_name = field
            rgb_images.append(obs[field_name][sub_field_name].numpy())
        else:
            rgb_images.append(obs[field].numpy())
    
    # å°†RGBå›¾åƒå±…ä¸­å¯¹é½å¹¶å¡«å……åˆ°ç›¸åŒå°ºå¯¸åæ‹¼æ¥
    padded_rgb_images = center_pad_images_to_max_size(rgb_images)
    concat_rgb = np.concatenate(padded_rgb_images, axis=1)
    
    # æå–å¹¶å¤„ç†æ·±åº¦å›¾åƒ
    depth_images = []
    if len(config["depth_fields"]) > 0:
      for field in config["depth_fields"]:
        depth_img = obs[field].numpy()
        color_depth = depth_to_color_img(depth_img)
        depth_images.append(color_depth)
      
      # å°†æ·±åº¦å›¾åƒå±…ä¸­å¯¹é½å¹¶å¡«å……åˆ°ç›¸åŒå°ºå¯¸åæ‹¼æ¥
      padded_depth_images = center_pad_images_to_max_size(depth_images)
      concat_depth = np.concatenate(padded_depth_images, axis=1)
    else:
      concat_depth = np.zeros_like(concat_rgb)
    
    return Image.fromarray(concat_rgb), Image.fromarray(concat_depth)

def process_episode(episode, episode_idx, config):
    """å¤„ç†å•ä¸ªepisode"""
    # è·å–è¯­è¨€æŒ‡ä»¤
    lang_inst = get_language_instruction(episode, config)
    if lang_inst == "":
        return None
    
    print(f"Language Instruction: {lang_inst}")
    
    # åŠ¨æ€è°ƒæ•´å¸§æŠ½å–
    total_frames = len(list(episode['steps']))
    frame_skip = FRAME_SKIP_LARGE if total_frames > LARGE_FRAME_THRESHOLD else FRAME_SKIP_DEFAULT
    print(f"å½“å‰episodeæ€»å¸§æ•°: {total_frames}, æŠ½å–å¸§æ•°: {frame_skip}")
    
    # æ”¶é›†å›¾åƒ
    rgb_images = []
    depth_images = []
    
    for step_idx, step in enumerate(episode["steps"]):
        if step_idx % frame_skip == 0:
            obs = step[config["observation_field"]]
            rgb_img, depth_img = process_single_step(obs, config)
            rgb_images.append(rgb_img)
            # depth_images.append(depth_img)
    
    # ç”Ÿæˆæ–‡ä»¶å
    safe_filename = lang_inst.replace(" ", "_").replace(".", "")
    rgb_path = f"{OUTPUT_DIR}/{safe_filename}_{episode_idx}_image.gif"
    depth_path = f"{OUTPUT_DIR}/{safe_filename}_{episode_idx}_depth.gif"
    
    # ä¿å­˜GIF
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    display.Image(as_gif(rgb_images, rgb_path, RESIZE_FACTOR))
    # display.Image(as_gif(depth_images, depth_path, RESIZE_FACTOR))
    print(f"å·²ç”ŸæˆGIFæ–‡ä»¶: {rgb_path}, {depth_path}")
    
    return {
        "total_frames": total_frames,
        "processed_frames": len(rgb_images),
        "rgb_path": rgb_path,
        "depth_path": depth_path
    }

# äººä¸ºé…ç½®

df = pd.read_csv('/home2/qrchen/embodied-datasets/metadata.csv')

TRAIN_SPLIT = 'train[:100]'  
FRAME_SKIP_DEFAULT = 5
RESIZE_FACTOR = 1
MAX_EPISODES = 100
FRAME_SKIP_LARGE = 10  # å½“å¸§æ•°>100æ—¶ä½¿ç”¨
LARGE_FRAME_THRESHOLD = 100
THIRD_PERSON_FRAME_THRESHOLD = 1000

# å¤šæ•°æ®é›†é…ç½®
DATASET_CONFIGS = {
    "conqhose": {
        "dataset_name_in_csv": "conqhose",
        "language_field": "language_instruction",
        "observation_field": "observation",
        "image_fields": ['frontleft_fisheye_image',"frontright_fisheye_image","hand_color_image"],
        "depth_fields": []
    },
    "FMB":{
        "dataset_name_in_csv": "FMB",
        "language_field": "language_instruction",
        "observation_field": "observation",
        "image_fields": ["image_side_1", "image_side_2", "image_wrist_1", "image_wrist_2"],
        "depth_fields": []
    },
    "Mobile-ALOHA":{
        "dataset_name_in_csv": "Mobile ALOHA",
        "language_field": "language_instruction",
        "observation_field": "observation",
        "image_fields": ['cam_high',"cam_left_wrist","cam_right_wrist"],
        "depth_fields": []
    },
    "MimicPlay":{
        "dataset_name_in_csv": "MimicPlay",
        "language_field": "language_instruction",
        "observation_field": "observation",
        "image_fields": [
            ("image", "front_image_1"),
            ("image", "front_image_2"), 
            ("wrist_image", "wrist_image")
        ],
        "depth_fields": []
    },
    "IO-AI":{
        "dataset_name_in_csv": "IO-AI",
        "language_field": "language_instruction",
        "observation_field": "observation",
        "image_fields": ["image_fisheye","image","image_left_side", "image_right_side"],
        "depth_fields": []
    },
    "RoboSet":{
        "dataset_name_in_csv": "RoboSet",
        "language_field": "language_instruction",
        "observation_field": "observation",
        "image_fields": ["image_left","image_right","image_top","image_wrist"],
        "depth_fields": []
    }
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šæ•°æ®é›†é…ç½®
    # "å¦ä¸€ä¸ªæ•°æ®é›†åç§°": {
    #     "dataset_name_in_csv": "å¦ä¸€ä¸ªæ•°æ®é›†åç§°",
    #     "language_field": "å¯¹åº”çš„è¯­è¨€å­—æ®µ",
    #     "version": "1.0.0",
    #     "observation_field": "å¯¹åº”çš„è§‚å¯Ÿå­—æ®µ",
    #     "image_fields": ['å¯¹åº”çš„å›¾åƒå­—æ®µ'],
    #     "depth_fields": ['å¯¹åº”çš„æ·±åº¦å­—æ®µ']
    # }
}

# éå†æ‰€æœ‰æ•°æ®é›†é…ç½®
for dataset_key, DATASET_CONFIG in DATASET_CONFIGS.items():
    print(f"\n{'='*60}")
    print(f"å¼€å§‹å¤„ç†æ•°æ®é›†: {dataset_key}")
    print(f"{'='*60}")
    
    # ä»df ä¸­æ‰¾åˆ° DATASET_CONFIG ä¸­ dataset_name_in_csv å¯¹åº”çš„ è¡Œï¼Œå¾—åˆ°å…¶ä¸­ nickname çš„å€¼
    dataset_name_in_csv = DATASET_CONFIG["dataset_name_in_csv"]
    dataset = df[df['Datasets'] == dataset_name_in_csv]
    
    if dataset.empty:
        print(f"è­¦å‘Š: åœ¨metadata.csvä¸­æœªæ‰¾åˆ°æ•°æ®é›† {dataset_name_in_csv}ï¼Œè·³è¿‡æ­¤æ•°æ®é›†")
        continue
        
    dataset = dataset['NickName'].item()
    
    OUTPUT_DIR = f"Trajectories/{dataset}/sample"

    # æ„å»ºæ•°æ®
    try:
        b = tfds.builder_from_directory(builder_dir=dataset2path(dataset))
        ds = b.as_dataset(split=TRAIN_SPLIT).shuffle(1000, seed=42)
        
        # æ‰“å° ds æœ‰å¤šå°‘æ¡
        print(f"ds æœ‰å¤šå°‘æ¡: {len(ds)}")
        
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•åŠ è½½æ•°æ®é›† {dataset}ï¼Œé”™è¯¯ä¿¡æ¯: {e}")
        continue

    # ç»Ÿè®¡æ•°æ®
    
    # 1. ç»Ÿè®¡åŠ¨è¯å’ŒåŠ¨è¯çŸ­è¯­
    frame_num = []
    task_list = []
    
    # 2. ç»Ÿè®¡å¸§æ•°å’Œæ”¶é›†instruction
    def get_instructions_and_frame_stats(ds):
        task_list = []
        frame_num = []
        for episode_idx, episode in tqdm(enumerate(ds)):
            step_0 = list(episode['steps'])[0]
            if 'natural_language_instruction' in step_0['observation']:
                task = step_0['observation']['natural_language_instruction'].numpy().decode('utf-8')
            elif 'language_instruction' in step_0:
                task = step_0['language_instruction'].numpy().decode('utf-8')
            else:
                instruction_bytes = step_0["observation"]["instruction"]
                instruction_encoded = tf.strings.unicode_encode(instruction_bytes, output_encoding="UTF-8")
                task = tf.strings.split(instruction_encoded, "\x00")[0].numpy().decode('utf-8')
            task_list.append(task)
            frame_num.append(len(list(episode['steps'])))
        return task_list, frame_num
    task_list, frame_num = get_instructions_and_frame_stats(ds)

    # 3. ç»Ÿè®¡å¸§æ•°å‡å€¼å’Œæ ‡å‡†å·®
    # æ¯ä¸€ä¸ªepisodeç»Ÿè®¡å¸§æ•°å‡å€¼å’Œæ ‡å‡†å·®
    mean_frames = np.mean(frame_num) if frame_num else 0
    std_frames = np.std(frame_num) if frame_num else 0
    print("--------------------------------")
    print(f"Mean frames per episode: {mean_frames:.2f}")
    print(f"Standard deviation of frames: {std_frames:.2f}")
    print(f"æ€»episodeæ•°: {len(frame_num)}ï¼Œæ€»instructionæ•°: {len(task_list)}ï¼Œå»é‡åinstructionæ•°: {len(set(task_list))}")
    print("--------------------------------")
    print(f"æ‰€æœ‰instructionçš„æ•°é‡:{len(task_list)}")
    print(f"æ‰€æœ‰çš„instruction: {task_list}")
    print(f"æ‰€æœ‰çš„instructionå»é‡åæ•°: {len(set(task_list))}")
    print(f"æ‰€æœ‰çš„instructionå»é‡å:")
    for i in set(task_list):
        print(i)
    print(Counter(task_list))

    # ç”Ÿäº§å¯¹åº”çš„gif å›¾ç‰‡
    save_root = f"/home2/qrchen/embodied-datasets/Trajectories/{dataset}"
    os.makedirs(os.path.join(save_root, "samples"), exist_ok=True)

    frame_skip = 10

    # æ¯ä¸ªtask æœ€å¤šçš„ trajectory æ•°
    MAX_TRAJECTORIES_PER_TASK = 4
    # æœ€å¤šç”Ÿæˆå¤šå°‘ä¸ªtaskï¼Œå¦‚æœä¸€å…±æœ‰100 ä¸ªtaskï¼Œé‚£ä¹ˆæˆ‘ä»¬åªä¼šè¾“å‡º MAX_TASKS ä¸ªtask
    MAX_TASKS = 10

    # 1. ç»Ÿè®¡æ¯ä¸ªä»»åŠ¡çš„è½¨è¿¹æ•°
    file_name_list = [] # æ¯ä¸ªtask çš„ trajectory æ•°
    task_counters = defaultdict(list) # æ¯ä¸ªtask çš„ trajectory æ•°
    for key in Counter(task_list):
        if len(key):
            task_counters[key]

    for episode_idx, episode in tqdm(enumerate(ds)):

        # 2.1 å¦‚æœä»»åŠ¡æ•°è¶…è¿‡æœ€å¤§ä»»åŠ¡æ•°ï¼Œåˆ™è·³è¿‡
        if sum(1 for lst in task_counters.values() if len(lst) > 0) > MAX_TASKS:
            break

        task = ''
        step_0 = list(episode['steps'])[0]# è·å–è½¨è¿¹çš„ç¬¬ä¸€ä¸ªstep
        # 2.2 è·å–ä»»åŠ¡ éå† åµŒå¥—å­—å…¸
        if 'natural_language_instruction' in step_0['observation']: 
            task = step_0['observation']['natural_language_instruction'].numpy().decode('utf-8')
        elif 'language_instruction' in step_0:
            task = step_0['language_instruction'].numpy().decode('utf-8')
        else:
            instruction_bytes = step_0["observation"]["instruction"]
            instruction_encoded = tf.strings.unicode_encode(instruction_bytes, output_encoding="UTF-8")
            task = tf.strings.split(instruction_encoded, "\x00")[0].numpy().decode('utf-8')

        # 2.3 å¦‚æœä»»åŠ¡ä¸ºç©ºï¼Œåˆ™è·³è¿‡  
        if not len(task):
            continue

        # 2.4 å¦‚æœä»»åŠ¡æ•°è¶…è¿‡æœ€å¤§ä»»åŠ¡æ•°ï¼Œåˆ™è·³è¿‡
        if task in task_counters and len(task_counters[task]) >= MAX_TRAJECTORIES_PER_TASK:
            continue

        rgb_images = []
        for step_index ,step in enumerate(episode['steps']):
            if step_index % frame_skip == 0:
                obs = step[DATASET_CONFIG["observation_field"]]
                rgb_img, depth_img = process_single_step(obs, DATASET_CONFIG) #è¿™é‡Œæ‰ç”¨äº† process_single_step å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°åœ¨ debug-xintong.ipynb ä¸­
                rgb_images.append(rgb_img)

        if task not in task_counters or len(task_counters[task]) < MAX_TRAJECTORIES_PER_TASK:
            if rgb_images:
                task_filename = task.replace(" ", "_").replace(".", "")
                
                current_count = len(task_counters[task])
                gif_path= os.path.join(save_root, "samples", task_filename, f"{current_count}.gif")
                os.makedirs(os.path.dirname(gif_path), exist_ok=True)
                task_counters[task].append(f"{current_count}.gif")
                display.Image(as_gif(rgb_images, gif_path, RESIZE_FACTOR))

    print(f"ä»»åŠ¡è®¡æ•°å™¨: {task_counters}")

    # ç”Ÿæˆjson æ–‡ä»¶å’Œ
    with open('/home2/qrchen/embodied-datasets/Templates/script.js', 'r', encoding='utf-8') as f:
        js_template = Template(f.read())

    filled_js = js_template.render(
        gif_paths=pprint.pformat(dict(task_counters))
    )

    with open(os.path.join(save_root, 'script.js'), 'w', encoding='utf-8') as f:
        f.write(filled_js)

    # ç”Ÿæˆ index.html æ–‡ä»¶
    with open("/home2/qrchen/embodied-datasets/Templates/index.html", "r", encoding="utf-8") as f:
        html_content = f.read()

    dataset_name_in_csv = DATASET_CONFIG["dataset_name_in_csv"]
    metadata = df[df['Datasets'] == dataset_name_in_csv] #å¾—åˆ°è¿™ä¸€è¡Œçš„æ•°æ®

    episodes = metadata['#Trajectories'].item().replace('\n', '<br>')
    language_instructions = metadata['Language instructions'].item().replace('\n', '<br>')

    how_to_modify = metadata['How to modify it to align with our overall objectives?'].item().replace('\n', '<br>')
    contents = f"""
    <div class="info-section">
        <h3>Task Information</h3>
        <div class="info-box">
            <p>
                <span class="highlight-label">#UniqueTasks:</span> {metadata['#UniqueTasks'].item()}
                <br><br>
                <span class="highlight-label">Language Instructions:</span> {language_instructions}
            </p>
        </div>
    </div>

    <div class="info-section">
        <h3>Scene Information</h3>
        <div class="info-box">
            <p>
                <span class="highlight-label">#Scenes:</span> {metadata['#Scenes'].item()}
                <br><br>
                <span class="highlight-label">Scene Description:</span> {metadata['Scenes'].item()}
            </p>
        </div>
    </div>

    <div class="info-section">
        <h3>View Information</h3>
        <div class="info-box">
            <p>
                <span class="highlight-label"># Total Cams:</span> {int(float(metadata['# Total Cams'].item()))}
                <br>
                <span class="highlight-label"># Depth Cams:</span> {int(float(metadata['# Depth Cams'].item()))}
                <br>
                <span class="highlight-label">ğŸ“„ First-person Cams:</span> {int(float(metadata['# First-person Cams'].item()))}
                <br>
                <span class="highlight-label">ğŸ“„ Third-person Cams:</span> {int(float(metadata['# Third-person Cams'].item()))}
            </p>
        </div>
    </div>

    <div class="info-section">
        <h3>Dataset Size</h3>
        <div class="info-box">
            <p>
                <span class="highlight-label">#Episodes:</span> {episodes}
                <br>
                <span class="highlight-label">Avg Frames per episode:</span> {metadata['Avg. frames/trajectory'].item()}
            </p>
        </div>
    </div>

    <div class="info-section">
        <h3>How to modify?</h3>
        <div class="info-box">
            <p>
                {how_to_modify}
            </p>
        </div>
    </div>
    """

    html_content = html_content.replace("==TITLE==", metadata["Datasets"].item())
    html_content = html_content.replace("==STRUCTURE==", metadata["Full data structure"].item())
    html_content = html_content.replace("==Contents==", contents)

    # ä¿å­˜åˆ°æ–°è·¯å¾„
    with open(os.path.join(save_root, 'index.html'), 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"æ•°æ®é›† {dataset_key} å¤„ç†å®Œæˆ!")
    print(f"è¾“å‡ºç›®å½•: {save_root}")

# æ‰€æœ‰æ•°æ®é›†å¤„ç†å®Œæˆ
print(f"\n{'='*60}")
print("æ‰€æœ‰æ•°æ®é›†å¤„ç†å®Œæˆ!")
print(f"{'='*60}")

# ç¨‹åºç»“æŸï¼Œæ¸…ç†æ—¥å¿—é‡å®šå‘
print("=" * 50)
print(f"ç¨‹åºæ‰§è¡Œå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"æ‰€æœ‰è¾“å‡ºå·²ä¿å­˜åˆ°: {log_file_path}")

# æ¢å¤åŸå§‹stdoutå¹¶å…³é—­æ—¥å¿—æ–‡ä»¶
sys.stdout = original_stdout
log_file.close()

print(f"æ—¥å¿—æ–‡ä»¶å·²ä¿å­˜: {log_file_path}")